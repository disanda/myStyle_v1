DATASET:
  PART_COUNT: 8
  PATH: /efs/user/pidhorss/celeba/data_fold_%d_lod_%d.pkl
MODEL:
  LATENT_SPACE_SIZE: 512
  LAYER_COUNT: 6
  MAX_CHANNEL_COUNT: 512
  START_CHANNEL_COUNT: 128
  DLATENT_AVG_BETA: 0.995
  MAPPING_LAYERS: 8
OUTPUT_DIR: results
TRAIN:
  BASE_LEARNING_RATE: 0.0015
  EPOCHS_PER_LOD: 6
  LEARNING_DECAY_RATE: 0.1
  LEARNING_DECAY_STEPS: []
  TRAIN_EPOCHS: 36
  LOD_2_BATCH_8GPU: [512, 256, 128,   64,   32,    32]
  LOD_2_BATCH_4GPU: [512, 256, 128,   64,   32,    16]
  LOD_2_BATCH_2GPU: [256, 256, 128,   64,   32,    16]
  LOD_2_BATCH_1GPU: [128, 128, 128,   64,   32,    16]
